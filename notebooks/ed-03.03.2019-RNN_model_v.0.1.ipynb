{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import importlib\n",
    "if '/opt/notebooks/' not in sys.path:\n",
    "    sys.path.append('/opt/notebooks/')\n",
    "\n",
    "try: importlib.reload(sl)\n",
    "except: import synt_lib as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = sl.get_dirs()\n",
    "M_PARAMS = sl.get_model_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = 256*256#16#M_PARAMS['QUANTIZATION_CHANNELS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_2:0' shape=(161664,) dtype=int32>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(Xs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_17:0' shape=(161663,) dtype=int32>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161661,) (161661,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([26276, 28012, 29522, 29522, 27018], dtype=int32),\n",
       " array([28012, 29522, 29522, 27018, 27018], dtype=int32))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_fnames = Path(DIRS['RAW_DATA']).rglob(\"*.wav\")\n",
    "Xs = []\n",
    "Ys = []\n",
    "for idx, fname in enumerate(wav_fnames):\n",
    "    if idx==n_files: break\n",
    "    audio = sl.load_audio_not_one_hot(fname.as_posix(), quantization_channels=quant)\n",
    "    Xs.append(audio[:-1])\n",
    "    Ys.append(audio[1:])\n",
    "    \n",
    "X = tf.concat(Xs,axis=0)\n",
    "Y = tf.concat(Ys,axis=0)\n",
    "print(X.shape, Y.shape)\n",
    "X[1000:1005].eval(session=sess), Y[1000:1005].eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = int(np.log2(quant))\n",
    "n = 2**(nbits//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c, X_f = X//n, X%n\n",
    "Y_c, Y_f = Y//n, Y%n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c, X_f, Y_c, Y_f = tuple(map(lambda x: (x-128)/128, [X_c, X_f, Y_c, Y_f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_73:0' shape=(161660,) dtype=float64>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(161661, 1) dtype=float64>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_X = tf.concat([tf.reshape(X_c[:-1], (-1,1)), tf.reshape(X_f[:-1], (-1,1)), tf.reshape(X_c[1:], (-1,1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_32:0' shape=(161660, 3) dtype=float64>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = X_c[1000:1010].eval(session=sess).reshape(-1,1)\n",
    "f = X_f[1000:1010].eval(session=sess).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = np.concatenate([c[:-1],f[:-1], c[1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.203125 ,  0.28125  , -0.1484375],\n",
       "       [-0.1484375, -0.15625  , -0.1015625],\n",
       "       [-0.1015625, -0.359375 , -0.1015625],\n",
       "       [-0.1015625, -0.359375 , -0.1796875],\n",
       "       [-0.1796875,  0.078125 , -0.1796875],\n",
       "       [-0.1796875,  0.078125 ,  0.       ],\n",
       "       [ 0.       , -1.       , -0.1015625],\n",
       "       [-0.1015625, -0.359375 , -0.1484375],\n",
       "       [-0.1484375, -0.15625  , -0.1484375]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.203125 , -0.1484375, -0.1015625, -0.1015625, -0.1796875,\n",
       "        -0.1796875,  0.       , -0.1015625, -0.1484375, -0.1484375]),\n",
       " array([ 0.28125 , -0.15625 , -0.359375, -0.359375,  0.078125,  0.078125,\n",
       "        -1.      , -0.359375, -0.15625 , -0.15625 ]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 10#M_PARAMS['SAMPLE_RATE']\n",
    "batch_size = 5\n",
    "num_batches = 5#total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Model_0.1'):\n",
    "    batchX_placeholder = tf.placeholder(tf.float32, [None, truncated_backprop_length, quant])\n",
    "    batchY_placeholder = tf.placeholder(tf.int32, [None, truncated_backprop_length, quant])\n",
    "    init_state = tf.placeholder(tf.float32, [None, quant])\n",
    "    \n",
    "    W = tf.Variable(np.random.rand(quant*2, quant), dtype=tf.float32)\n",
    "    b = tf.Variable(np.zeros((1,quant)), dtype=tf.float32)\n",
    "    \n",
    "    inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "    labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "    \n",
    "    # Forward pass\n",
    "    current_state = init_state\n",
    "    states_series = []\n",
    "    for current_input in inputs_series:\n",
    "        current_input = tf.reshape(current_input, [-1, quant])\n",
    "        input_and_state_concatenated = tf.concat([current_input, current_state], axis=1)  # Increasing number of columns\n",
    "\n",
    "        next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "        states_series.append(next_state)\n",
    "        current_state = next_state\n",
    "    \n",
    "    losses = [tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels) for logits, labels in zip(states_series,labels_series)]\n",
    "    total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "    train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in tqdm_notebook(range(num_epochs),desc='epochs'):\n",
    "        x,y = tf.concat([X for i in range(batch_size)],axis=0), tf.concat([Y for i in range(batch_size)],axis=0)\n",
    "        \n",
    "        _current_state = np.zeros((batch_size, quant))\n",
    "\n",
    "\n",
    "        for batch_idx in tqdm_notebook(range(num_batches),desc='batches',leave=False):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, states_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX.eval(session=sess),\n",
    "                    batchY_placeholder:batchY.eval(session=sess),\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
