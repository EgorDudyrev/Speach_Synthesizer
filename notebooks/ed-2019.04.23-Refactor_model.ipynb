{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "PARENT_DIR = os.path.realpath('..')\n",
    "import importlib\n",
    "if PARENT_DIR not in sys.path:\n",
    "    sys.path.append(PARENT_DIR)\n",
    "\n",
    "try: importlib.reload(sl)\n",
    "except: import synt_lib as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRS = sl.get_dirs(parent_dir=PARENT_DIR)\n",
    "M_PARAMS = sl.get_model_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = M_PARAMS['QUANTIZATION_CHANNELS']\n",
    "nbits = int(np.log2(quant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGRU:\n",
    "    \"\"\"Implementation of a Gated Recurrent Unit (GRU) as described in [1].\n",
    "    \n",
    "    [1] Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    input_dimensions: int\n",
    "        The size of the input vectors (x_t).\n",
    "    hidden_size: int\n",
    "        The size of the hidden layer vectors (h_t).\n",
    "    dtype: obj\n",
    "        The datatype used for the variables and constants (optional).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dimensions, hidden_size, dtype=tf.float64, variables_values_dict=None):\n",
    "        self.input_dimensions = input_dimensions\n",
    "        self.hidden_size = hidden_size\n",
    "        self.define_constants()\n",
    "        if variables_values_dict is None:\n",
    "            self.define_variables(dtype)\n",
    "        else:\n",
    "            self.restore_variables(variables_values_dict)\n",
    "        self.define_arithmetics()\n",
    "        self.define_train_variables()\n",
    "    \n",
    "    def define_constants(self):\n",
    "        # Mask for masking W matrixes\n",
    "        M = np.ones(shape=(self.input_dimensions, self.hidden_size))\n",
    "        M[2,:self.hidden_size//2]=0\n",
    "        self.M = tf.constant(shape=(self.input_dimensions, self.hidden_size), value=M)\n",
    "        \n",
    "    def define_variables(self, dtype):     \n",
    "        # Weights for input vectors of shape (input_dimensions, hidden_size)\n",
    "        self.Wr = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.input_dimensions, self.hidden_size), mean=0, stddev=0.01), name='Wr')\n",
    "        self.Wu = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.input_dimensions, self.hidden_size), mean=0, stddev=0.01), name='Wu')\n",
    "        self.We = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.input_dimensions, self.hidden_size), mean=0, stddev=0.01), name='We')\n",
    "        \n",
    "        # Weights for hidden vectors of shape (hidden_size, hidden_size)\n",
    "        self.Ur = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size, self.hidden_size), mean=0, stddev=0.01), name='Ur')\n",
    "        self.Uu = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size, self.hidden_size), mean=0, stddev=0.01), name='Uu')\n",
    "        self.Ue = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size, self.hidden_size), mean=0, stddev=0.01), name='Ue')\n",
    "        \n",
    "        # Biases for hidden vectors of shape (hidden_size,)\n",
    "        self.br = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size,), mean=0, stddev=0.01), name='br')\n",
    "        self.bu = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size,), mean=0, stddev=0.01), name='bu')\n",
    "        self.be = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size,), mean=0, stddev=0.01), name='be')\n",
    "        \n",
    "        # O's matrices\n",
    "        self.O1 = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size//2,self.hidden_size//2), mean=0, stddev=0.01), name='O1')\n",
    "        self.O3 = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size//2,self.hidden_size//2), mean=0, stddev=0.01), name='O3')\n",
    "        self.O2 = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size//2,self.hidden_size//2), mean=0, stddev=0.01), name='O2')\n",
    "        self.O4 = tf.Variable(tf.truncated_normal(dtype=dtype, shape=(self.hidden_size//2,self.hidden_size//2), mean=0, stddev=0.01), name='O4')\n",
    "    \n",
    "    def restore_variables(self, variables):\n",
    "        # Weights for input vectors of shape (input_dimensions, hidden_size)\n",
    "        self.Wr = tf.Variable(variables['Wr:0'], name='Wr')\n",
    "        self.Wu = tf.Variable(variables['Wu:0'], name='Wu')\n",
    "        self.We = tf.Variable(variables['We:0'], name='We')\n",
    "        \n",
    "        # Weights for hidden vectors of shape (hidden_size, hidden_size)\n",
    "        self.Ur = tf.Variable(variables['Ur:0'], name='Ur')\n",
    "        self.Uu = tf.Variable(variables['Uu:0'], name='Uu')\n",
    "        self.Ue = tf.Variable(variables['Ue:0'], name='Ue')\n",
    "        \n",
    "        # Biases for hidden vectors of shape (hidden_size,)\n",
    "        self.br = tf.Variable(variables['br:0'], name='br')\n",
    "        self.bu = tf.Variable(variables['bu:0'], name='bu')\n",
    "        self.be = tf.Variable(variables['be:0'], name='be')\n",
    "        \n",
    "        # O's matrices\n",
    "        self.O1 = tf.Variable(variables['O1:0'], name='O1')\n",
    "        self.O3 = tf.Variable(variables['O2:0'], name='O3')\n",
    "        self.O2 = tf.Variable(variables['O3:0'], name='O2')\n",
    "        self.O4 = tf.Variable(variables['O4:0'], name='O4')\n",
    "    \n",
    "    def define_arithmetics(self):\n",
    "        # Define the input layer placeholder\n",
    "        self.input_layer = tf.placeholder(dtype=tf.float64, shape=(None, None, self.input_dimensions), name='input')\n",
    "        #[c_t-1, f_t-1, c_t]\n",
    "        \n",
    "        # Put the time-dimension upfront for the scan operator\n",
    "        self.x_t = tf.transpose(self.input_layer, [1, 0, 2], name='x_t')\n",
    "        #[f_t-1, c_t-1, c_t]\n",
    "        \n",
    "        # A little hack (to obtain the same shape as the input matrix) to define the initial hidden state h_0\n",
    "        self.h_0 = tf.matmul(self.x_t[0, :, :], tf.zeros(dtype=tf.float64, shape=(self.input_dimensions, self.hidden_size)), name='h_0')\n",
    "        \n",
    "        # Perform the scan operator\n",
    "        self.h_t_transposed = tf.scan(self.forward_pass, self.x_t, initializer=self.h_0, name='h_t_transposed')\n",
    "        \n",
    "        self.y_c, self.y_f = tf.split(self.h_t_transposed, num_or_size_splits=2, axis=2)\n",
    "        # Transpose the result back\n",
    "        #self.h_t = tf.transpose(self.h_t_transposed, [1, 0, 2], name='h_t')\n",
    "        \n",
    "        self.P_ct = tf.scan(self.get_P_cs, self.y_c, name='calc_Pc')\n",
    "        self.c_t_transposed = tf.reduce_max(self.P_ct, axis=2)\n",
    "        self.c_t = tf.transpose(self.c_t_transposed)\n",
    "        self.P_ft = tf.scan(self.get_P_fs, self.y_f, name='calc_Pf')\n",
    "        self.f_t_transposed = tf.reduce_max(self.P_ft, axis=2)\n",
    "        self.f_t = tf.transpose(self.f_t_transposed)\n",
    "        \n",
    "        self.y = tf.stack([self.c_t, self.f_t], axis=2)\n",
    "    \n",
    "    def define_train_variables(self):\n",
    "        self.output = self.y\n",
    "        self.expected_output = tf.placeholder(\n",
    "            dtype=tf.float64, shape=(None, None, 2), name='expected_output'\n",
    "            #(batch_size, truncated_len, 2), name='expected_output'\n",
    "        )\n",
    "        #self.loss = tf.reduce_sum(0.5 * tf.pow(self.output - self.expected_output, 2)) / float(batch_size)\n",
    "        # mean(1/2 * (y-y_true)^2)\n",
    "        self.loss = tf.reduce_mean(0.5 * tf.pow(self.output - self.expected_output, 2))\n",
    "        self.train_step = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        \n",
    "    def get_P_cs(self, lastP, y_c):\n",
    "        return tf.nn.softmax( tf.matmul(tf.nn.relu(tf.matmul(y_c, self.O1)), self.O2), axis=1)\n",
    "    def get_P_fs(self, lastP, y_f):\n",
    "        return tf.nn.softmax( tf.matmul(tf.nn.relu(tf.matmul(y_f, self.O3)), self.O4), axis=1)\n",
    "        \n",
    "    def forward_pass(self, h_tm1, x_t):\n",
    "        \"\"\"Perform a forward pass.\n",
    "        Arguments\n",
    "        ---------\n",
    "        h_tm1: np.matrix\n",
    "            The hidden state at the previous timestep (h_{t-1}).\n",
    "        x_t: np.matrix\n",
    "            The input vector.\n",
    "        \"\"\"\n",
    "        # Definitions of z_t and r_t\n",
    "        u_t = tf.sigmoid(tf.matmul(h_tm1, self.Uu) + tf.matmul(x_t, tf.multiply(self.Wu, self.M)) + self.bu)\n",
    "        r_t = tf.sigmoid(tf.matmul(h_tm1, self.Ur) + tf.matmul(x_t, tf.multiply(self.Wr, self.M)) + self.br)\n",
    "        # Definition of h~_t\n",
    "        e_t = tf.tanh(tf.multiply(r_t, tf.matmul(h_tm1, self.Ue))\\\n",
    "                      +tf.matmul(x_t, tf.multiply(self.We, self.M))\\\n",
    "                      + self.be)\n",
    "        # Compute the next hidden state\n",
    "        h_t = tf.multiply(u_t, h_tm1) + tf.multiply(1 - u_t, e_t)\n",
    "        return h_t\n",
    "    \n",
    "    def train(self, X_train, Y_train, X_test, Y_test, session):\n",
    "        c_t = session.run(self.c_t, feed_dict={self.input_layer: X_train})\n",
    "        X_train[:,:,2] = c_t\n",
    "        # Compute the losses\n",
    "        _, train_loss = session.run([self.train_step, self.loss],\n",
    "                                 feed_dict={self.input_layer: X_train, self.expected_output: Y_train})\n",
    "        validation_loss = session.run(self.loss,\n",
    "                                   feed_dict={self.input_layer: X_test, self.expected_output: Y_test})\n",
    "        return train_loss, validation_loss\n",
    "    \n",
    "    def validate(self, X_val, Y_val, session):\n",
    "        c_t = session.run(self.c_t, feed_dict={self.input_layer: X_val})\n",
    "        X_val[:,:,2] = c_t\n",
    "        validation_loss = session.sun(self.loss,\n",
    "                                     feed_dict={self.input_layer: X_val, self.expected_output: Y_val})\n",
    "        return validation_loss\n",
    "    \n",
    "    def generate_sound(self, num_pieces, n_seconds, session, sample_rate=16000):\n",
    "        generated = np.array([0]*2*num_pieces).reshape(num_pieces,1,2)\n",
    "        curX = generated[:,-1,:].reshape(num_pieces,-1,2)\n",
    "        for i in tqdm_notebook(range(sample_rate*n_seconds)): # 1 seconds of 'speach'\n",
    "            curX = generated[:,-1,:].reshape(num_pieces,-1,2)\n",
    "            curX = np.concatenate([curX,np.array([[[0]]]*num_pieces) ],axis=2)\n",
    "            c_t = session.run(self.c_t, feed_dict={self.input_layer: curX})\n",
    "            curX[:,:,2] = c_t\n",
    "            curY = session.run(self.output, feed_dict={self.input_layer: curX})\n",
    "            generated = np.concatenate([generated, curY],axis=1)\n",
    "        gen_to_wav = generated*128+128\n",
    "        gen_to_wav = np.int32((gen_to_wav[:,:,0]*256+gen_to_wav[:,:,1]).round())\n",
    "        gen_to_wav = tf.convert_to_tensor(gen_to_wav)\n",
    "        return gen_to_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего файлов:\n",
    "* Обучение (cv-valid-train): 391552\n",
    "* cv-valid-dev: 8152\n",
    "* cv-valid-test: 7990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_fnames = list(Path(DIRS['RAW_DATA']).rglob(\"*.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input has 2 dimensions: dimension 0 is reserved for the first term and dimension 1 is reverved for the second term\n",
    "input_dimensions = 3\n",
    "\n",
    "# Arbitrary number for the size of the hidden state\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 secs per iteration => 1 min per 6 iters => 1 hour per 360 iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Refactored'\n",
    "if model_name not in os.listdir(DIRS['MODELS']):\n",
    "    os.mkdir(DIRS['MODELS']+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "gru = WaveGRU(input_dimensions, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_variables = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sl.load_data(wav_fnames, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100 161661 50\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "truncated_len = M_PARAMS['SAMPLE_RATE']//128\n",
    "total_series_length = int(X.shape[1])\n",
    "num_epochs = 50#total_series_length//batch_size//truncated_len\n",
    "print(batch_size, truncated_len, total_series_length, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_early_stopping = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c369c1a9ed45729a8818af9e4cd764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the losses\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_variables)\n",
    "    O1_before = gru.O1.eval(session=sess)\n",
    "    \n",
    "    # Perform all the iterations\n",
    "    for epoch in tqdm_notebook(range(epoch_start, epoch_start+num_epochs)):\n",
    "        X_train, Y_train, X_test, Y_test = sl.get_train_test(X, batch_size, truncated_len, sess)\n",
    "        train_loss, validation_loss = gru.train(X_train, Y_train, X_test, Y_test, sess)\n",
    "\n",
    "        # Log the losses\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "        if validation_loss>max(validation_losses[-n_early_stopping:]):\n",
    "            print(f'Early stopped at {epoch} epoch')\n",
    "            break\n",
    "        \n",
    "        # Display an update every 50 iterations\n",
    "        if epoch % 50 == 0:\n",
    "            sl.plot_losses(train_losses, validation_losses,\n",
    "                        title='Iteration: %d, train loss: %.4f, test loss: %.4f' % (epoch, train_loss, validation_loss))\n",
    "            plt.show()\n",
    "            saver.save(sess, DIRS['MODELS']+model_name+'/checkpoint',global_step=epoch,write_meta_graph=False)\n",
    "        \n",
    "    sl.plot_losses(train_losses, validation_losses,\n",
    "                title='Iteration: %d, train loss: %.4f, test loss: %.4f' % (epoch, train_loss, validation_loss))\n",
    "    plt.show()\n",
    "        \n",
    "    saver.save(sess, DIRS['MODELS']+model_name+'/final')\n",
    "    \n",
    "    O1_after = gru.O1.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(DIRS['MODELS']+model_name+'/final.meta')\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(DIRS['MODELS']+model_name))\n",
    "    restored_variables = {x.name:x.eval(session=sess) for x in tf.global_variables()[:13]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "gru = WaveGRU(input_dimensions, hidden_size, variables_values_dict=restored_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sl.load_data(wav_fnames, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(DIRS['MODELS']+model_name+'/final.meta')\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(DIRS['MODELS']+model_name))\n",
    "    restored_variables = {x.name:x.eval(session=sess) for x in tf.global_variables()[:13]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "gru = WaveGRU(input_dimensions, hidden_size, variables_values_dict=restored_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sl.load_data(wav_fnames, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 100 161661 50\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "truncated_len = 100#M_PARAMS['SAMPLE_RATE']\n",
    "total_series_length = int(X.shape[1])\n",
    "num_epochs = 50#400#total_series_length//batch_size//truncated_len\n",
    "print(batch_size, truncated_len, total_series_length, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_variables = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_variables)\n",
    "    O1_restored = gru.O1.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "for idx, O in enumerate([('before training',O1_before),\n",
    "                         ('after training', O1_after),\n",
    "                         ('restored', O1_restored)]):\n",
    "    title, O = O\n",
    "    plt.subplot(1,3,idx+1)\n",
    "    sns.heatmap(O, center=0, cmap='RdBu_r')\n",
    "    plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_variables)\n",
    "    gen_to_wav = gru.generate_sound(num_pieces=1, n_seconds=2, session=sess, sample_rate=M_PARAMS['SAMPLE_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_variables)\n",
    "    #plt.plot(audio.eval(session=sess), label='real')\n",
    "    plt.plot(gen_to_wav[0].eval(session=sess), label='generated')\n",
    "plt.plot(np.int32([np.sin(x/1000)*16000+32256 for x in range(gen_to_wav.shape[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_variables)\n",
    "    sl.write_audio_not_one_hot(audio=gen_to_wav[0], filename='output_0.wav', session=sess, quantization_channels=quant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
